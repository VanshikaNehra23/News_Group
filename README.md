# News_Group

. Imported the dataset and converted it to dataframe 
. Scraped 2 websites using BeautifulSoup
. Conveted the scraped text to dataframe named testing
. Added b_labels according to the categories to both train and test data
. Conveted text of the train and test data into unique tokens using Tokenizer
. Created Model Usinf LSTM
. created news.csv file (file size too large to upload)
. Trained and fitted the model (Not Complete.... Error showing RAM Full)
. Plotted the loss per iteration and accuracy per iteration
